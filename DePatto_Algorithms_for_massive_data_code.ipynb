{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# algorithms for massive data - market-basket analysis on amazon books reviews"
      ],
      "metadata": {
        "id": "nTPIoL_XUqMf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## libraries import"
      ],
      "metadata": {
        "id": "x35wLuegglOs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, size, udf, array_contains, explode, row_number\n",
        "from pyspark.sql.types import ArrayType, StringType\n",
        "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, NGram\n",
        "from pyspark.ml.fpm import FPGrowth\n",
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from pyspark.sql.window import Window\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from collections import Counter\n",
        "import time\n",
        "import pandas as pd\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
      ],
      "metadata": {
        "id": "Qkj_gUx6xN7D"
      },
      "execution_count": 146,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# NLTK downloads for lemmatization\n",
        "nltk.download('wordnet')\n",
        "nltk.download('omw-1.4')"
      ],
      "metadata": {
        "id": "6B9bIuu3eIre",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffe92644-4c34-4aa9-c1a3-05d43f5cd687"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]   Package omw-1.4 is already up-to-date!\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 147
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## general parameters"
      ],
      "metadata": {
        "id": "OWZ-Slj5geBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "SAMPLE_SIZE = 0.01 # dataset sample fraction\n",
        "SEED = 42 # random seed\n",
        "MIN_SUPPORT = 0.01 # minumum support threshold for frequent itemset\n",
        "MIN_CONFIDENCE = 0.2 # minimum confidence threshold for association rules"
      ],
      "metadata": {
        "id": "uPP6tlhriYZ4"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# words to keep in the analysis and used for obtaining meaningful bigrams.\n",
        "# basically here we have words that will be removed from the most frequent words\n",
        "# that are going to be searched automatically and removed. also these words are usefull because\n",
        "# a bigram will be considered into our final basket if and only if one of the 2 words\n",
        "# in the bigram is contained into this list.\n",
        "\n",
        "KEEP_WORDS = {\"good\", \"great\", \"excellent\", \"amazing\", \"wonderful\", \"brilliant\", \"fantastic\",\n",
        "              \"bad\", \"terrible\", \"awful\", \"disappointing\", \"boring\", \"dull\", \"most\",\n",
        "              \"love\", \"like\", \"hate\", \"best\", \"worst\", \"favorite\", \"recommended\",\n",
        "              \"well\", \"interesting\", \"better\", \"easy\", \"recommend\", \"must\", \"high\",\n",
        "              \"highly\",\"very\", \"really\", \"quite\", \"much\", \"many\", \"lot\", \"enjoy\", \"prefer\",\n",
        "}"
      ],
      "metadata": {
        "id": "f8BghxsMnKcT"
      },
      "execution_count": 149,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# words to be removed. include common stopwors and terms that could lead to insignificant\n",
        "# words associations like 'higly' comporting 'recommended'.\n",
        "# this list is a second iteration after the automatic stopwords removal based on frequency\n",
        "\n",
        "BAN_TOKENS = {\n",
        "    \"take\", \"point\", \"last\", \"school\", \"young\", \"year\", \"get\", \"even\", \"something\",\n",
        "    \"way\", \"make\", \"all\", \"just\", \"being\", \"over\", \"both\", \"through\", \"yourselves\", \"its\",\n",
        "    \"before\", \"herself\", \"had\", \"should\", \"to\", \"only\", \"under\", \"ours\", \"has\", \"tell\",\n",
        "    \"do\", \"them\", \"his\", \"they\", \"not\", \"during\", \"now\", \"him\", \"nor\", \"writing\", \"seem\",\n",
        "    \"did\", \"this\", \"she\", \"each\", \"further\", \"where\", \"few\", \"because\", \"doing\", \"become\",\n",
        "    \"some\", \"are\", \"our\", \"ourselves\", \"out\", \"what\", \"for\", \"while\", \"does\", \"look\",\n",
        "    \"above\", \"between\", \"t\", \"be\", \"we\", \"who\", \"were\", \"here\", \"hers\", \"by\", \"use\",\n",
        "    \"on\", \"about\", \"of\", \"against\", \"s\", \"or\", \"own\", \"into\", \"yourself\", \"down\", \"try\",\n",
        "    \"your\", \"from\", \"her\", \"their\", \"there\", \"been\", \"whom\", \"too\", \"themselves\",\n",
        "    \"was\", \"until\", \"more\", \"himself\", \"that\", \"but\", \"don\", \"with\", \"written\", \"leave\",\n",
        "    \"those\", \"he\", \"me\", \"myself\", \"these\", \"will\", \"below\", \"can\", \"going\", \"may\",\n",
        "    \"theirs\", \"my\", \"and\", \"then\", \"is\", \"am\", \"it\", \"an\", \"as\", \"itself\", \"at\", \"keep\",\n",
        "    \"have\", \"in\", \"any\", \"if\", \"again\", \"no\", \"when\", \"how\", \"other\", \"also\", \"go\",\n",
        "    \"which\", \"you\", \"after\", \"such\", \"why\", \"a\", \"off\", \"i\", \"yours\", \"always\",\n",
        "    \"so\", \"the\", \"having\", \"once\", \"ago\", \"know\", \"want\", \"think\", \"find\", \"thing\",\n",
        "    \"ever\", \"two\", \"end\", \"call\", \"first\", \"page\", \"found\", \"than\", \"another\",\n",
        "    \"work\", \"see\", \"give\", \"every\", \"come\", \"say\", \"put\", \"still\", \"would\",\n",
        "    \"day\", \"back\", \"made\", \"though\", \"however\", \"read\", \"later\", \"one\", \"need\"\n",
        "}"
      ],
      "metadata": {
        "id": "WLGqB2nqqJ0p"
      },
      "execution_count": 150,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## data imports"
      ],
      "metadata": {
        "id": "sa0IOh5LTnKp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ['KAGGLE_USERNAME'] = \"antdepa\"\n",
        "os.environ['KAGGLE_KEY'] = \"bb4586df4d1661596f68edd3d214b0c0\""
      ],
      "metadata": {
        "id": "MErFeJMmK0Ri"
      },
      "execution_count": 151,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "zip_path = \"./data/amazon-books-reviews.zip\"\n",
        "csv_path = \"./data/Books_rating.csv\""
      ],
      "metadata": {
        "id": "2giYZPK1K3ge"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# dataset download if not preset\n",
        "\n",
        "if not os.path.exists(zip_path) and not os.path.exists(csv_path):\n",
        "    os.system(\"kaggle datasets download -d mohamedbakhet/amazon-books-reviews -p ./data\")"
      ],
      "metadata": {
        "id": "vAQ-o-IKK5Dm"
      },
      "execution_count": 153,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# extraction of the csv format dataset from the zip file if needed\n",
        "if not os.path.exists(csv_path):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as z:\n",
        "        for file in z.namelist():\n",
        "            if \"Books_rating.csv\" in file:\n",
        "                z.extract(file, \"./data\")\n",
        "                os.rename(f\"./data/{file}\", csv_path)"
      ],
      "metadata": {
        "id": "BEvi85ziK6Xn"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## spark session initialization"
      ],
      "metadata": {
        "id": "egBn-siI7CU6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder.appName(\"Frequent_items\") \\\n",
        "    .master(\"local[*]\") \\\n",
        "    .getOrCreate()"
      ],
      "metadata": {
        "id": "25SzqDVeK72i"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sampled dataset\n",
        "\n",
        "books = spark.read.csv(csv_path, header=True, inferSchema=True).sample(SAMPLE_SIZE,SEED)"
      ],
      "metadata": {
        "id": "GkSH-ma7K9Bw"
      },
      "execution_count": 156,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books.show(10)"
      ],
      "metadata": {
        "id": "FKe_dcVmLAR4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "39a6082b-7d09-4dd8-f8e7-c46140ee1b80"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "|0312322291|King James: Belie...| NULL|          NULL|                NULL|               2/2|         5.0| 1118188800|Yo Homie this is ...|\"LeBron James is ...|\n",
            "|B0006D6DRK|Open marriage;: A...| NULL|A3KBF2S2MGN48O|\"T. Thompson \"\"&#...|               2/2|         4.0| 1188604800|A Must Read for a...|This book is a cl...|\n",
            "|0671551345|Night World: Daug...| NULL|          NULL|                NULL|               0/0|         5.0|  889920000|The most charming...|The plot and char...|\n",
            "|B0008852GG|The soul of man u...| NULL| AMVC9WTXYKNJ1|\"J. Edgar Mihelic...|               1/3|         4.0| 1294099200|An interesting li...|Although the titl...|\n",
            "|0836204271|Close to Home Rev...| NULL|A3QXDJQIHNGKMH|  rudorfer@erols.com|               2/4|         5.0|  881971200|HeeeHHHAAAAAAAHHH...|This book is the ...|\n",
            "|0932813062|Lost Cities of Af...|11.66|A1LG9LE8NN47CZ|    Winston Whitaker|               6/7|         5.0|  953510400|There's no other ...|There is no other...|\n",
            "|B0006AUI9W|Lincoln reconside...| NULL|A1E8EIKF5T05BO|             Panhard|               0/0|         5.0| 1356739200|Not your ordinary...|\"According to the...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A1JA55BW3T7WZJ|        S. J Mahoney|               2/4|         4.0| 1293321600|Law of unintended...|Hazlitt is one of...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A3W1J0KZJJPG5J|\"A. J. Morrison \"...|               0/0|         5.0| 1355184000|       nice resource|Teacher no longer...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A2PIHPON1FXK7M|   Michelle D. Lasch|               6/6|         5.0| 1317340800|If you want to un...|\"Economics in One...|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "books.count()"
      ],
      "metadata": {
        "id": "7VYx0lGKLBUs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bae1f7a9-43d2-4eff-b641-5df3c4d068bb"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "30332"
            ]
          },
          "metadata": {},
          "execution_count": 158
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## null values handling"
      ],
      "metadata": {
        "id": "LSMeZCAmpKbc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# keep only reviews where the content is not null and not just empty whitespace\n",
        "\n",
        "books_clean = books.filter(\n",
        "    (~col('review/text').isNull()) &  # condition: 'review/text' must NOT be null\n",
        "    (~col('review/text').rlike(r'^\\s*$'))  # condition: 'review/text' must NOT be empty or only whitespace\n",
        ")"
      ],
      "metadata": {
        "id": "4gGeoopwLCgS"
      },
      "execution_count": 159,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "books_clean.show(10)"
      ],
      "metadata": {
        "id": "hLLLrnnUkYsI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb14ff13-7ce3-4647-bb86-9a6321af1111"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "|0312322291|King James: Belie...| NULL|          NULL|                NULL|               2/2|         5.0| 1118188800|Yo Homie this is ...|\"LeBron James is ...|\n",
            "|B0006D6DRK|Open marriage;: A...| NULL|A3KBF2S2MGN48O|\"T. Thompson \"\"&#...|               2/2|         4.0| 1188604800|A Must Read for a...|This book is a cl...|\n",
            "|0671551345|Night World: Daug...| NULL|          NULL|                NULL|               0/0|         5.0|  889920000|The most charming...|The plot and char...|\n",
            "|B0008852GG|The soul of man u...| NULL| AMVC9WTXYKNJ1|\"J. Edgar Mihelic...|               1/3|         4.0| 1294099200|An interesting li...|Although the titl...|\n",
            "|0836204271|Close to Home Rev...| NULL|A3QXDJQIHNGKMH|  rudorfer@erols.com|               2/4|         5.0|  881971200|HeeeHHHAAAAAAAHHH...|This book is the ...|\n",
            "|0932813062|Lost Cities of Af...|11.66|A1LG9LE8NN47CZ|    Winston Whitaker|               6/7|         5.0|  953510400|There's no other ...|There is no other...|\n",
            "|B0006AUI9W|Lincoln reconside...| NULL|A1E8EIKF5T05BO|             Panhard|               0/0|         5.0| 1356739200|Not your ordinary...|\"According to the...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A1JA55BW3T7WZJ|        S. J Mahoney|               2/4|         4.0| 1293321600|Law of unintended...|Hazlitt is one of...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A3W1J0KZJJPG5J|\"A. J. Morrison \"...|               0/0|         5.0| 1355184000|       nice resource|Teacher no longer...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A2PIHPON1FXK7M|   Michelle D. Lasch|               6/6|         5.0| 1317340800|If you want to un...|\"Economics in One...|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+\n",
            "only showing top 10 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokenization"
      ],
      "metadata": {
        "id": "r7sRsbz81SDW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenization of the text by non-word characters and later convert it to lowercase\n",
        "\n",
        "tokenizer = RegexTokenizer(\n",
        "    inputCol=\"review/text\",\n",
        "    outputCol=\"tokens\",\n",
        "    pattern=r\"\\W+\", # split on non-word characters\n",
        "    toLowercase=True\n",
        ")"
      ],
      "metadata": {
        "id": "-ZGlOXCDd-UC"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenized = tokenizer.transform(books_clean)"
      ],
      "metadata": {
        "id": "MUcmP4SjkK_D"
      },
      "execution_count": 162,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## lemmatization"
      ],
      "metadata": {
        "id": "KH92PXEOsufX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()"
      ],
      "metadata": {
        "id": "FHWYdsbLsyEP"
      },
      "execution_count": 163,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def lemmatize_tokens(tokens):\n",
        "    if not tokens:\n",
        "        return []\n",
        "    return [lemmatizer.lemmatize(t) for t in tokens]"
      ],
      "metadata": {
        "id": "WKpUikbStFXF"
      },
      "execution_count": 164,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatize_udf = udf(lemmatize_tokens, ArrayType(StringType()))"
      ],
      "metadata": {
        "id": "yx_VM9Z5tGWc"
      },
      "execution_count": 165,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_lemmatized = tokenized.withColumn(\"tokens_lem\", lemmatize_udf(col(\"tokens\")))"
      ],
      "metadata": {
        "id": "NCHaBcB8tHpv"
      },
      "execution_count": 166,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## stopwords"
      ],
      "metadata": {
        "id": "IZxMvivQva0e"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "stopwords_remover = StopWordsRemover(\n",
        "    inputCol=\"tokens_lem\",\n",
        "    outputCol=\"tokens_nostopwords\"\n",
        ")"
      ],
      "metadata": {
        "id": "XKqxdWLCvdY-"
      },
      "execution_count": 167,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_stopwords = stopwords_remover.transform(tokens_lemmatized)"
      ],
      "metadata": {
        "id": "-5VMMNkkvft-"
      },
      "execution_count": 168,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## frequent words to be removed"
      ],
      "metadata": {
        "id": "c8URVI7C1obv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_top_frequent_words(spark_df, col_name=\"tokens_nostopwords\", top_n=20):\n",
        "    freqs = (spark_df\n",
        "             .select(explode(col(col_name)).alias(\"token\"))\n",
        "             .groupBy(\"token\")\n",
        "             .count()\n",
        "             .orderBy(col(\"count\").desc())\n",
        "             .limit(top_n))\n",
        "    return [row['token'] for row in freqs.collect()]"
      ],
      "metadata": {
        "id": "3Z-SCZlzyxZU"
      },
      "execution_count": 169,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "auto_stopwords = set(get_top_frequent_words(no_stopwords, \"tokens_nostopwords\", top_n=50))"
      ],
      "metadata": {
        "id": "lbtbEN_TsymY"
      },
      "execution_count": 170,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Stopwords filtered:\", sorted(list(auto_stopwords)))"
      ],
      "metadata": {
        "id": "CH3ORp66kZAR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "092314fc-b249-4501-904d-a5a3e0533c64"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords filtered: ['also', 'author', 'best', 'book', 'character', 'doe', 'even', 'find', 'first', 'found', 'get', 'go', 'good', 'great', 'ha', 'know', 'life', 'like', 'little', 'love', 'm', 'make', 'many', 'much', 'never', 'new', 'novel', 'one', 'page', 'people', 'quot', 'read', 'reader', 'reading', 'really', 'see', 'story', 'take', 'thing', 'think', 'time', 'two', 'wa', 'want', 'way', 'well', 'work', 'world', 'written', 'year']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto_stopwords = auto_stopwords - KEEP_WORDS # remove words that are explicitly KEEP_WORDS"
      ],
      "metadata": {
        "id": "9KTbUeLfAbcQ"
      },
      "execution_count": 172,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Stopwords filtered:\", sorted(list(auto_stopwords)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlGV4RdEAfjY",
        "outputId": "799d472e-d2b0-4ded-f2a4-8f293e5a51b4"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stopwords filtered: ['also', 'author', 'book', 'character', 'doe', 'even', 'find', 'first', 'found', 'get', 'go', 'ha', 'know', 'life', 'little', 'm', 'make', 'never', 'new', 'novel', 'one', 'page', 'people', 'quot', 'read', 'reader', 'reading', 'see', 'story', 'take', 'thing', 'think', 'time', 'two', 'wa', 'want', 'way', 'work', 'world', 'written', 'year']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto_stopwords = auto_stopwords - {\"author\", \"character\", \"novel\", \"story\"}"
      ],
      "metadata": {
        "id": "ExK5lRqB-0TW"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def filter_tokens(tokens):\n",
        "    if not tokens:\n",
        "        return [] # return [] if input is empty\n",
        "\n",
        "    words_to_remove = (auto_stopwords | BAN_TOKENS) - KEEP_WORDS\n",
        "\n",
        "    # keep tokens that are:\n",
        "    # - not in words_to_remove\n",
        "    # - longer than 2 chars\n",
        "    # - not purely digits\n",
        "    return [t for t in tokens\n",
        "            if t not in words_to_remove\n",
        "            and len(t) > 2\n",
        "            and not t.isdigit()]\n"
      ],
      "metadata": {
        "id": "PVrfJleM06k5"
      },
      "execution_count": 175,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_udf = udf(filter_tokens, ArrayType(StringType()))"
      ],
      "metadata": {
        "id": "hjzHHIVi08Wh"
      },
      "execution_count": 176,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokens_filtered = no_stopwords.withColumn(\"tokens_filtered\", filter_udf(col(\"tokens_nostopwords\")))"
      ],
      "metadata": {
        "id": "niH-2Y_p0-zb"
      },
      "execution_count": 177,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## bigrams"
      ],
      "metadata": {
        "id": "eVh0wiNz1wCW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "bigram = NGram(n=2, inputCol=\"tokens_filtered\", outputCol=\"bigrams_raw\")"
      ],
      "metadata": {
        "id": "im12Gg0H804t"
      },
      "execution_count": 178,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with_bigrams = bigram.transform(tokens_filtered)"
      ],
      "metadata": {
        "id": "Sdh8K3No82nN"
      },
      "execution_count": 179,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# return only bigrams that start with a negative word, joined by '_'\n",
        "\n",
        "def filter_neg_bigrams(bigrams):\n",
        "    if not bigrams or not isinstance(bigrams, list):\n",
        "        return []\n",
        "\n",
        "    NEGATIVE_STARTERS = {\"didnt\", \"dont\", \"never\", \"cannot\", \"no\", \"not\", \"wont\", \"isnt\", \"wasnt\", \"couldnt\", \"shouldnt\"}\n",
        "    result = []\n",
        "\n",
        "    for bg in bigrams:\n",
        "        w1, w2 = bg.split()\n",
        "        if w1 in NEGATIVE_STARTERS:\n",
        "            result.append(f\"{w1}_{w2}\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "dH2woCeU3xNO"
      },
      "execution_count": 180,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "filter_didnt_bigrams_udf = udf(filter_neg_bigrams, ArrayType(StringType()))"
      ],
      "metadata": {
        "id": "3rnOTBmx35gO"
      },
      "execution_count": 181,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with_bigrams = with_bigrams.withColumn(\"meaningful_bigrams\", filter_didnt_bigrams_udf(col(\"bigrams_raw\")))"
      ],
      "metadata": {
        "id": "oWJuBK0H37Rq"
      },
      "execution_count": 182,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## tokens and bigrams combination"
      ],
      "metadata": {
        "id": "g9lKe-dpT4Xr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combine_tokens_bigrams(tokens, bigrams):\n",
        "    tokens = tokens or []\n",
        "    bigrams = bigrams or []\n",
        "    return list(dict.fromkeys(tokens + bigrams))"
      ],
      "metadata": {
        "id": "VF7mbxHly_Ea"
      },
      "execution_count": 183,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combine_udf = udf(combine_tokens_bigrams, ArrayType(StringType()))"
      ],
      "metadata": {
        "id": "Qx0myUB9zA90"
      },
      "execution_count": 184,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined = with_bigrams.withColumn(\"basket\", combine_udf(col(\"tokens_filtered\"), col(\"meaningful_bigrams\")))"
      ],
      "metadata": {
        "id": "Zljr0wdHerfo"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## sample baskets"
      ],
      "metadata": {
        "id": "w1_86hYQUkar"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "combined.show(20, truncate=True)"
      ],
      "metadata": {
        "id": "YfoaInMbebNk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b9792fb-9038-45c4-bab5-37fe8a20c7f2"
      },
      "execution_count": 186,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+\n",
            "|        Id|               Title|Price|       User_id|         profileName|review/helpfulness|review/score|review/time|      review/summary|         review/text|              tokens|          tokens_lem|  tokens_nostopwords|     tokens_filtered|         bigrams_raw|meaningful_bigrams|              basket|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+\n",
            "|0312322291|King James: Belie...| NULL|          NULL|                NULL|               2/2|         5.0| 1118188800|Yo Homie this is ...|\"LeBron James is ...|[lebron, james, i...|[lebron, james, i...|[lebron, james, b...|[lebron, james, b...|[lebron james, ja...|                []|[lebron, james, b...|\n",
            "|B0006D6DRK|Open marriage;: A...| NULL|A3KBF2S2MGN48O|\"T. Thompson \"\"&#...|               2/2|         4.0| 1188604800|A Must Read for a...|This book is a cl...|[this, book, is, ...|[this, book, is, ...|[book, classic, p...|[classic, pertain...|[classic pertains...|                []|[classic, pertain...|\n",
            "|0671551345|Night World: Daug...| NULL|          NULL|                NULL|               0/0|         5.0|  889920000|The most charming...|The plot and char...|[the, plot, and, ...|[the, plot, and, ...|[plot, character,...|[plot, character,...|[plot character, ...|                []|[plot, character,...|\n",
            "|B0008852GG|The soul of man u...| NULL| AMVC9WTXYKNJ1|\"J. Edgar Mihelic...|               1/3|         4.0| 1294099200|An interesting li...|Although the titl...|[although, the, t...|[although, the, t...|[although, title,...|[although, title,...|[although title, ...|                []|[although, title,...|\n",
            "|0836204271|Close to Home Rev...| NULL|A3QXDJQIHNGKMH|  rudorfer@erols.com|               2/4|         5.0|  881971200|HeeeHHHAAAAAAAHHH...|This book is the ...|[this, book, is, ...|[this, book, is, ...|[book, best, funn...|[best, funny, fel...|[best funny, funn...|                []|[best, funny, fel...|\n",
            "|0932813062|Lost Cities of Af...|11.66|A1LG9LE8NN47CZ|    Winston Whitaker|               6/7|         5.0|  953510400|There's no other ...|There is no other...|[there, is, no, o...|[there, is, no, o...|[book, africa, ar...|[africa, arabia, ...|[africa arabia, a...|                []|[africa, arabia, ...|\n",
            "|B0006AUI9W|Lincoln reconside...| NULL|A1E8EIKF5T05BO|             Panhard|               0/0|         5.0| 1356739200|Not your ordinary...|\"According to the...|[according, to, t...|[according, to, t...|[according, autho...|[according, autho...|[according author...|                []|[according, autho...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A1JA55BW3T7WZJ|        S. J Mahoney|               2/4|         4.0| 1293321600|Law of unintended...|Hazlitt is one of...|[hazlitt, is, one...|[hazlitt, is, one...|[hazlitt, one, pr...|[hazlitt, promine...|[hazlitt prominen...|                []|[hazlitt, promine...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A3W1J0KZJJPG5J|\"A. J. Morrison \"...|               0/0|         5.0| 1355184000|       nice resource|Teacher no longer...|[teacher, no, lon...|[teacher, no, lon...|[teacher, longer,...|[teacher, longer,...|[teacher longer, ...|                []|[teacher, longer,...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A2PIHPON1FXK7M|   Michelle D. Lasch|               6/6|         5.0| 1317340800|If you want to un...|\"Economics in One...|[economics, in, o...|[economics, in, o...|[economics, one, ...|[economics, lesso...|[economics lesson...|                []|[economics, lesso...|\n",
            "|B0007H4QBK|Economics in one ...| NULL| AXRKTEF6OGLH8|    Roberto Helguera|               1/3|         5.0| 1199923200|Best Book in Econ...|A great and acces...|[a, great, and, a...|[a, great, and, a...|[great, accessibl...|[great, accessibl...|[great accessible...|                []|[great, accessibl...|\n",
            "|B0007H4QBK|Economics in one ...| NULL|A1QAV7F38KSNTC|       \"MTS \"\"MTS\"\"\"|               3/7|         5.0| 1298678400|Criticizing what ...|I have to laugh a...|[i, have, to, lau...|[i, have, to, lau...|[laugh, negative,...|[laugh, negative,...|[laugh negative, ...|                []|[laugh, negative,...|\n",
            "|B0007H4QBK|Economics in one ...| NULL| AXBM8YO0N0K1X|       George Kucera|               3/4|         5.0| 1300233600|Brilliant and Cog...|Henry Hazlitt was...|[henry, hazlitt, ...|[henry, hazlitt, ...|[henry, hazlitt, ...|[henry, hazlitt, ...|[henry hazlitt, h...|                []|[henry, hazlitt, ...|\n",
            "|B0008AGXVW|Tales from silver...| NULL| ABJBDHC6PZ588|\"spacedog \"\"space...|               1/1|         3.0| 1309132800|fairly entertaini...|i enjoy folk/fair...|[i, enjoy, folk, ...|[i, enjoy, folk, ...|[enjoy, folk, fai...|[enjoy, folk, fai...|[enjoy folk, folk...|                []|[enjoy, folk, fai...|\n",
            "|B000NRYUHO|      Edge of Danger| NULL|A3ARWQ6170EOKS|  \"MKF \"\"marilynf\"\"\"|               1/1|         1.0| 1023148800|Edge of Danger by...|I was a big fan o...|[i, was, a, big, ...|[i, wa, a, big, f...|[wa, big, fan, ja...|[big, fan, jack, ...|[big fan, fan jac...|                []|[big, fan, jack, ...|\n",
            "|B000NRYUHO|      Edge of Danger| NULL|A2EUG1L6NDL6V6|       J. Ray Topper|               1/2|         1.0|  989280000|Can't believe the...|A terrible, child...|[a, terrible, chi...|[a, terrible, chi...|[terrible, childi...|[terrible, childi...|[terrible childis...|                []|[terrible, childi...|\n",
            "|B000NRYUHO|      Edge of Danger| NULL|A17C80R77KI3ZM|   Wayne S. Schwartz|               2/4|         1.0| 1151452800|           Two Hacks|I don't know who ...|[i, don, t, know,...|[i, don, t, know,...|[know, worse, hig...|[worse, higgins, ...|[worse higgins, h...|                []|[worse, higgins, ...|\n",
            "|0971198500|My Dog's Life: A ...| NULL|          NULL|                NULL|              9/10|         5.0| 1031702400| Helping the Healing|Our four-year-old...|[our, four, year,...|[our, four, year,...|[four, year, old,...|[four, old, dog, ...|[four old, old do...|                []|[four, old, dog, ...|\n",
            "|B000N6DDJQ|The Scarlet Lette...| NULL|A3HCIFUNCSUN4A|       tricia walker|               0/0|         4.0| 1339632000|  the scarlet letter|this book is womd...|[this, book, is, ...|[this, book, is, ...|[book, womderful,...|[womderful, enjoy...|[womderful enjoye...|      [didnt_like]|[womderful, enjoy...|\n",
            "|B000N6DDJQ|The Scarlet Lette...| NULL|A35R1DF8A7AITI|     Jacqueline Chan|               0/2|         3.0| 1168473600|         It's Decent|I am truly amazed...|[i, am, truly, am...|[i, am, truly, am...|[truly, amazed, o...|[truly, amazed, n...|[truly amazed, am...|                []|[truly, amazed, n...|\n",
            "+----------+--------------------+-----+--------------+--------------------+------------------+------------+-----------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+--------------------+------------------+--------------------+\n",
            "only showing top 20 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sample_baskets = combined.take(100)\n",
        "all_items = []\n",
        "for basket in sample_baskets:\n",
        "    all_items.extend(basket['basket'])\n",
        "\n",
        "bigram_items = [item for item in all_items if '_' in item]\n",
        "single_items = [item for item in all_items if '_' not in item]\n",
        "\n",
        "print(f\"Bigrams found: {len(set(bigram_items))}\")\n",
        "print(f\"Single token: {len(set(single_items))}\")\n",
        "print(f\"Bigram examples: {sorted(set(bigram_items))[:5]}\")"
      ],
      "metadata": {
        "id": "7SpSPprb--oK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8297fcf-39b0-4d54-843c-903f92db709a"
      },
      "execution_count": 187,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bigrams found: 3\n",
            "Single token: 2201\n",
            "Bigram examples: ['didnt_anything', 'didnt_like', 'didnt_mind']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## FPGrowth model for frequent itemsets"
      ],
      "metadata": {
        "id": "BXAZjXquUuI2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fpGrowth = FPGrowth(itemsCol=\"basket\", minSupport=MIN_SUPPORT, minConfidence=MIN_CONFIDENCE)"
      ],
      "metadata": {
        "id": "CnyCAstVUND0"
      },
      "execution_count": 188,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = fpGrowth.fit(combined)"
      ],
      "metadata": {
        "id": "RDey5C_ftkqW"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# display frequent itemsets, association rules, and predictions\n",
        "\n",
        "print(\"Frequent Itemsets:\")\n",
        "model.freqItemsets.orderBy(\"freq\", ascending=False).show(truncate=False)\n",
        "\n",
        "print(\"Association Rules:\")\n",
        "model.associationRules.orderBy(\"confidence\", ascending=False).show(truncate=False)\n",
        "\n",
        "print(\"Predictions:\")\n",
        "predictions = model.transform(combined)\n",
        "predictions.orderBy(\"prediction\", ascending=False).show(5, truncate=False)"
      ],
      "metadata": {
        "id": "0VQGJKXmUOrp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "68833f57-6f84-4bb1-d3c6-dab9f96a33ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.associationRules.filter((col(\"lift\") > 1.2) & (col(\"confidence\") > 0.3)).show(truncate=False) # filtering rules with strong lift and confidence"
      ],
      "metadata": {
        "id": "zDjy5CZUwk3h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "windowSpec = Window.orderBy(col(\"confidence\").desc())"
      ],
      "metadata": {
        "id": "0Lx2tSpbvd8p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules_with_index = model.associationRules.withColumn(\"row_num\", row_number().over(windowSpec))"
      ],
      "metadata": {
        "id": "UbMGKwxxvgH5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules_with_index.filter(col(\"row_num\") > 20).show(truncate=False)"
      ],
      "metadata": {
        "id": "2jWw5r285inC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules_with_index.filter(col(\"row_num\") > 40).show(truncate=False)"
      ],
      "metadata": {
        "id": "ALcM1f-HvUPS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rules_with_index.filter(col(\"row_num\") > 60).show(truncate=False)"
      ],
      "metadata": {
        "id": "YJmmOrV-vVVd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## visualizations"
      ],
      "metadata": {
        "id": "MBh-ka7-2K_v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "freq_itemsets = model.freqItemsets.toPandas()\n",
        "assoc_rules = model.associationRules.toPandas()"
      ],
      "metadata": {
        "id": "CZHcbokVfiuB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_items = freq_itemsets.sort_values(by=\"freq\", ascending=False).head(20) # top 20 frequent itemsets\n",
        "top_items['items_str'] = top_items['items'].apply(lambda x: ', '.join(x))"
      ],
      "metadata": {
        "id": "QlheL1Vfk1e4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=\"freq\", y=\"items_str\", data=top_items, palette=\"summer\")\n",
        "plt.title(\"Top 20 Frequent Itemsets\")\n",
        "plt.xlabel(\"Frequency\")\n",
        "plt.ylabel(\"Itemset\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "28wLXckBgGwV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_rules = assoc_rules.sort_values(by=\"confidence\", ascending=False).head(20) # top 20 association rules\n",
        "top_rules['rule_str'] = top_rules['antecedent'].apply(lambda x: ', '.join(x)) + \" -> \" + top_rules['consequent'].apply(lambda x: ', '.join(x))"
      ],
      "metadata": {
        "id": "I-uy5l4Ik4Cc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "sns.barplot(x=\"confidence\", y=\"rule_str\", data=top_rules, palette=\"summer\")\n",
        "plt.title(\"Top 20 Association Rules\")\n",
        "plt.xlabel(\"Confidence\")\n",
        "plt.ylabel(\"Rule\")\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "DwausZ0igIiZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## parameter sensitivity analysis"
      ],
      "metadata": {
        "id": "EbXOh9isVRUW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# performs a grid search over different minSupport and minConfidence values\n",
        "\n",
        "def parameter_sensitivity_analysis(combined_df):\n",
        "    support_values = [0.005, 0.01, 0.02]\n",
        "    confidence_values = [0.1, 0.2, 0.3]\n",
        "    results = []\n",
        "\n",
        "    for support in support_values:\n",
        "        for confidence in confidence_values:\n",
        "            print(f\"\\nTesting: Support={support}, Confidence={confidence}\")\n",
        "            start = time.time()\n",
        "\n",
        "            # fit the model with the given support and confidence\n",
        "            model = FPGrowth(itemsCol=\"basket\", minSupport=support, minConfidence=confidence).fit(combined_df)\n",
        "\n",
        "            # count frequent itemsets and association rules\n",
        "            num_itemsets = model.freqItemsets.count()\n",
        "            num_rules = model.associationRules.count()\n",
        "\n",
        "            # measure time\n",
        "            final_time = time.time() - start\n",
        "\n",
        "            results.append({\n",
        "                \"support\": support,\n",
        "                \"confidence\": confidence,\n",
        "                \"num_itemsets\": num_itemsets,\n",
        "                \"num_rules\": num_rules,\n",
        "                \"training_time\": final_time\n",
        "            })\n",
        "\n",
        "            print(f\"Itemsets: {num_itemsets:,}\")\n",
        "            print(f\"Rules: {num_rules:,}\")\n",
        "            print(f\"Time: {final_time:.2f}s\")\n",
        "\n",
        "    return pd.DataFrame(results)"
      ],
      "metadata": {
        "id": "Nd8O2iUAhDNl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "param_results = parameter_sensitivity_analysis(combined)\n",
        "print(\"\\n-------------------summary table-------------------\")\n",
        "print(param_results.to_string(index=False))"
      ],
      "metadata": {
        "id": "G2is4kWpVlHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# heatmaps for sensitivity analysis\n",
        "\n",
        "fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
        "\n",
        "# heatmap 1: number of frequent itemsets for each support-confidence combination\n",
        "pivot_itemsets = param_results.pivot(index='support', columns='confidence', values='num_itemsets')\n",
        "sns.heatmap(pivot_itemsets, annot=True, fmt='d', ax=axes[0,0], cmap='summer')\n",
        "axes[0,0].set_title('Number of Frequent Itemsets')\n",
        "\n",
        "# heatmap 2: number of association rules for each support-confidence combination\n",
        "pivot_rules = param_results.pivot(index='support', columns='confidence', values='num_rules')\n",
        "sns.heatmap(pivot_rules, annot=True, fmt='d', ax=axes[0,1], cmap='summer')\n",
        "axes[0,1].set_title('Number of Association Rules')\n",
        "\n",
        "# heatmap 3: training time in seconds for each parameter combination\n",
        "pivot_time = param_results.pivot(index='support', columns='confidence', values='training_time')\n",
        "sns.heatmap(pivot_time, annot=True, fmt='.2f', ax=axes[1,0], cmap='summer')\n",
        "axes[1,0].set_title('Training Time (seconds)')\n",
        "\n",
        "# heatmap 4: ratio of rules per itemset for each combination\n",
        "param_results['rules_per_itemset'] = param_results['num_rules'] / param_results['num_itemsets']\n",
        "pivot_ratio = param_results.pivot(index='support', columns='confidence', values='rules_per_itemset')\n",
        "sns.heatmap(pivot_ratio, annot=True, fmt='.2f', ax=axes[1,1], cmap='summer')\n",
        "axes[1,1].set_title('Rules per Itemset Ratio')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "uX2nRkEN28ga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}